const natural = require('natural');
const stopword = require('stopword');
const crypto = require('crypto');
const Groq = require('groq-sdk').default;
require('dotenv').config();

const groqClient = new Groq({
  apiKey: process.env.GROQ_API_KEY
});

let knowledgeBase = [];

function initializeKnowledgeBase() {
  if (knowledgeBase.length) return;
  // â€¦ Push your 42 entries here, each with:
  //   image: '/assets/<machine>/<filename>.gif',
  //   source: 'knowledge-base'
}

function preprocessQuery(q) {
  const tokens = new natural.WordTokenizer().tokenize(q.toLowerCase());
  const filtered = stopword.removeStopwords(tokens);
  return filtered.map(t => natural.PorterStemmer.stem(t));
}

function calculateRelevance(item, tokens) {
  const text = [item.problem, ...item.causes, ...item.solutions, ...item.keywords]
    .join(' ')
    .toLowerCase();
  let score = 0;
  tokens.forEach(token => {
    if (text.includes(token)) score += 1;
    else if (token.length > 3 && text.includes(token.slice(0, 4))) score += 0.5;
  });
  return tokens.length ? score / tokens.length : 0;
}

/**
 * Search troubleshooting entries, optionally falling back to Groq LLM.
 *
 * @param {string} query
 * @param {string} machineType
 * @param {boolean} noLLM      // if true, never call Groq API
 */
async function searchTroubleshooting(query, machineType, noLLM = false) {
  initializeKnowledgeBase();

  const tokens = preprocessQuery(query);
  let results = knowledgeBase
    .filter(i => i.machineType === machineType && calculateRelevance(i, tokens) > 0.1)
    .map(i => ({ ...i, relevance: calculateRelevance(i, tokens) }))
    .sort((a, b) => b.relevance - a.relevance)
    .slice(0, 5);

  // If no KB hits and AI fallback allowed, call GROQ chat completion
  if (!results.length && query.trim() && !noLLM) {
    console.log('Invoking Groq LLM for:', machineType, query);

    try {
      const response = await groqClient.chat.completions.create({
        model: 'llama-3.3-70b-versatile',       // or another deployed model
        messages: [
          {
            role: 'system',
            content: `You are a technical expert on ${machineType} machines.`
          },
          {
            role: 'user',
            content: `Troubleshoot: ${query}\n\nProvide a numbered, step-by-step guide.`
          }
        ]
      });

      const aiText = response.choices?.[0]?.message?.content || '';
      const aiSteps = aiText
        .split('\n')
        .filter(line => /^\d+\./.test(line.trim()))
        .map(line => line.replace(/^\d+\.\s*/, '').trim());

      results = [{
        id: `llm-${crypto.randomUUID()}`,
        machineType,
        problem: query,
        causes: ['Generated by AI'],
        solutions: ['Generated by AI'],
        steps: aiSteps.length ? aiSteps : ['No steps generated.'],
        keywords: query.split(/\s+/),
        image: '',                // no static image for AI
        source: 'llm',
        relevance: 0
      }];
    } catch (err) {
      console.error('Groq LLM error:', err);
    }
  }

  return { query, results, totalFound: results.length };
}

function getIssuesByMachine(machineType) {
  initializeKnowledgeBase();
  return knowledgeBase
    .filter(i => i.machineType === machineType)
    .map(i => ({ id: i.id, problem: i.problem }));
}

module.exports = { getIssuesByMachine, searchTroubleshooting };



